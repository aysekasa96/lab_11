# lab_11
# Mijn ervaring met Azure Synapse Analytics en Apache Spark Notebook

Door deze opdracht te voltooien, heb ik waardevolle ervaring opgedaan met het automatiseren van gegevensverwerking in Azure Synapse Analytics en het uitvoeren van grootschalige datatransformaties met Apache Spark Notebooks. 🎯 Hier is wat ik heb geleerd:

## 📌 Samenvatting van mijn leerproces
### 1️⃣ Gebruik van Apache Spark Notebook
- Ik heb geleerd hoe ik een Spark Notebook in Synapse Studio kan maken en uitvoeren.
- Ik heb het Notebook in een pipeline opgenomen om het datatransformatieproces te automatiseren.

### 2️⃣ Datatransformatie
- Ik heb geleerd hoe ik verkoopgegevens uit CSV-bestanden kan lezen en omzetten naar het Parquet-formaat.
- Ik heb klantennamen opgesplitst om de gegevens beter te organiseren.

### 3️⃣ Automatisering met Azure Synapse Pipelines
- Ik heb geleerd hoe ik een pipeline kan maken en configureren.
- Met triggers heb ik de pipeline ingesteld om op specifieke tijden of gebeurtenissen te draaien.
- Door het gebruik van de pipeline-run-ID kon ik gegevens bij elke run in een unieke map opslaan.

### 4️⃣ Gegevensopslag en toegang
- Ik heb geleerd hoe ik Azure Data Lake Storage kan configureren en koppelen aan Synapse Analytics.
- Ik heb opslag en SQL-query’s gebruikt om getransformeerde gegevens te analyseren.

## 💡 Doel van deze opdracht
- Praktische ervaring opdoen met big data-verwerking in een realistische omgeving.
- Het begrijpen van gegevensengineering-processen en het verbeteren van automatiseringsvaardigheden.
- Professioneel leren werken met Azure Synapse Studio.

Deze opdracht heeft mijn technische vaardigheden verrijkt en mijn begrip van data-analyse en automatisering verdiept. 🚀
# Mijn ervaring met Azure Synapse Analytics en Apache Spark Notebook

Door deze opdracht te voltooien, heb ik waardevolle ervaring opgedaan met het automatiseren van gegevensverwerking in Azure Synapse Analytics en het uitvoeren van grootschalige datatransformaties met Apache Spark Notebooks. 🎯 Hier is wat ik heb geleerd:

## 📌 Samenvatting van mijn leerproces
### 1️⃣ Gebruik van Apache Spark Notebook
- Ik heb geleerd hoe ik een Spark Notebook in Synapse Studio kan maken en uitvoeren.
- Ik heb het Notebook in een pipeline opgenomen om het datatransformatieproces te automatiseren.

### 2️⃣ Datatransformatie
- Ik heb geleerd hoe ik verkoopgegevens uit CSV-bestanden kan lezen en omzetten naar het Parquet-formaat.
- Ik heb klantennamen opgesplitst om de gegevens beter te organiseren.

### 3️⃣ Automatisering met Azure Synapse Pipelines
- Ik heb geleerd hoe ik een pipeline kan maken en configureren.
- Met triggers heb ik de pipeline ingesteld om op specifieke tijden of gebeurtenissen te draaien.
- Door het gebruik van de pipeline-run-ID kon ik gegevens bij elke run in een unieke map opslaan.

### 4️⃣ Gegevensopslag en toegang
- Ik heb geleerd hoe ik Azure Data Lake Storage kan configureren en koppelen aan Synapse Analytics.
- Ik heb opslag en SQL-query’s gebruikt om getransformeerde gegevens te analyseren.

## 💡 Doel van deze opdracht
- Praktische ervaring opdoen met big data-verwerking in een realistische omgeving.
- Het begrijpen van gegevensengineering-processen en het verbeteren van automatiseringsvaardigheden.
- Professioneel leren werken met Azure Synapse Studio.

Deze opdracht heeft mijn technische vaardigheden verrijkt en mijn begrip van data-analyse en automatisering verdiept. 🚀
# Mijn ervaring met Azure Synapse Analytics en Apache Spark Notebook

Door deze opdracht te voltooien, heb ik waardevolle ervaring opgedaan met het automatiseren van gegevensverwerking in Azure Synapse Analytics en het uitvoeren van grootschalige datatransformaties met Apache Spark Notebooks. 🎯 Hier is wat ik heb geleerd:

## 📌 Samenvatting van mijn leerproces
### 1️⃣ Gebruik van Apache Spark Notebook
- Ik heb geleerd hoe ik een Spark Notebook in Synapse Studio kan maken en uitvoeren.
- Ik heb het Notebook in een pipeline opgenomen om het datatransformatieproces te automatiseren.

### 2️⃣ Datatransformatie
- Ik heb geleerd hoe ik verkoopgegevens uit CSV-bestanden kan lezen en omzetten naar het Parquet-formaat.
- Ik heb klantennamen opgesplitst om de gegevens beter te organiseren.

### 3️⃣ Automatisering met Azure Synapse Pipelines
- Ik heb geleerd hoe ik een pipeline kan maken en configureren.
- Met triggers heb ik de pipeline ingesteld om op specifieke tijden of gebeurtenissen te draaien.
- Door het gebruik van de pipeline-run-ID kon ik gegevens bij elke run in een unieke map opslaan.

### 4️⃣ Gegevensopslag en toegang
- Ik heb geleerd hoe ik Azure Data Lake Storage kan configureren en koppelen aan Synapse Analytics.
- Ik heb opslag en SQL-query’s gebruikt om getransformeerde gegevens te analyseren.

## 💡 Doel van deze opdracht
- Praktische ervaring opdoen met big data-verwerking in een realistische omgeving.
- Het begrijpen van gegevensengineering-processen en het verbeteren van automatiseringsvaardigheden.
- Professioneel leren werken met Azure Synapse Studio.


